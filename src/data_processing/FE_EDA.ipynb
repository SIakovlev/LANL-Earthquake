{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import os\n",
    "import h5py\n",
    "import dask.dataframe as dd\n",
    "import dask\n",
    "import tsfresh\n",
    "import plotly \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "plotly.tools.set_credentials_file(username='ptolmachev', api_key='Fs5sBFAg7YuBn52rzy6n')\n",
    "\n",
    "def downsample(df, take_every):\n",
    "    return df.loc[::take_every]\n",
    "\n",
    "def nice_plot(series):\n",
    "    fig = plt.figure(figsize = (16,4))\n",
    "    plt.grid(True)\n",
    "    try:\n",
    "        plt.plot(series.compute().tolist(), 'r-',linewidth = 2, alpha = 0.7)\n",
    "    except:\n",
    "        plt.plot(series.tolist(), 'r-',linewidth = 2, alpha = 0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./LANL-Earthquake-Prediction/train_downcasted.csv', index_col = False)\n",
    "print(df.info(memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.9 ms, sys: 20.4 ms, total: 49.3 ms\n",
      "Wall time: 49.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfs = []\n",
    "for i in range(3):\n",
    "    dfs.append(pd.read_hdf('./sample.h5', key = 'df'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/pavel/Documents/0Research/Projects/Kaggle/Signals before the earthquakes.html'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "def Three_EQ_comparison(featurised_df)\n",
    "data = [go.Scatter(y=downsample(dfs[i], 10).s+i*1000, opacity = 0.7) for i in range(3)]\n",
    "layout = dict(\n",
    "    title='Three Earthquakes'\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "plotly.offline.plot(fig, filename = \"Signals before the earthquakes.html\", auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DASK featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FUNCTIONS FOR COMPUTING FEATURES\n",
    "\n",
    "# def ema_sum(x, alpha = 0.9): #custom made function\n",
    "#     coeff = np.array([alpha**i for i in range(len(x))])*(1-alpha)/(1-alpha**(len(x)))\n",
    "#     return np.sum([x*c for x,c in zip(x,coeff)]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_hdf('/home/pavel/Documents/0Research/Projects/LANL-Earthquake/data/sample.h5', key = 'df'))\n",
    "df.columns = [\"s\",\"y\"]\n",
    "\n",
    "def rolling_window(series, window_size, stride, function, params = None):\n",
    "    len_series = len(series)\n",
    "    num_iter = int(np.ceil((len_series-window_size)/stride)+1) \n",
    "    \n",
    "    if params is None:\n",
    "        kwargs = {}\n",
    "    else:\n",
    "        kwargs = params\n",
    "    \n",
    "    shape = series.shape[:-1] + (series.shape[-1] - window_size + 1, window_size)\n",
    "    strides = series.strides + (series.strides[-1],)\n",
    "    iterator = iter(np.lib.stride_tricks.as_strided(series, shape=shape, strides=strides)[::stride])\n",
    "    res = 0*np.empty(num_iter, dtype = np.float)\n",
    "    \n",
    "    if hasattr(tsfresh.feature_extraction.feature_calculators, function):\n",
    "        modifier = \"tsfresh.feature_extraction.feature_calculators.\"\n",
    "    else:\n",
    "        modifier = \"\"\n",
    "\n",
    "    expression = modifier + function + \"(next(iterator), **kwargs)\"\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        try:\n",
    "            res[i] = np.float(eval(expression))\n",
    "        except StopIteration:\n",
    "            return res[:i]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_data(df,col_name, list_of_functions, list_of_params, window_sizes, stride, save_to, rewrite = True):\n",
    "    '''\n",
    "    Input: pandas array with signal representations\n",
    "    \n",
    "    Saves new pandas dataframe in hdf5 extension to \"save_to\" location\n",
    "    where the columns are the calculated over the time series features from the \"list_of_function\"\n",
    "    using windows from \"window_sizes\" and having a spesified stride\n",
    "    \"rewrite\" specifies wether to discard all the previous information wtitten to the featurized dataframe \n",
    "    '''\n",
    "    \n",
    "    #checks\n",
    "    if (len(list_of_functions) != len(list_of_params)) or (len(list_of_params) != len(window_sizes)):\n",
    "        raise ValueError(\"Parameters \\\"list_of_functions\\\", \\\n",
    "        \\\"list_of_params\\\" and \\\"window_sizes\\\" must have the same lengths!\")\n",
    "    if stride <=0 :\n",
    "        raise ValueError(\"The \\\"stride\\\" has to be a postivie number!\")\n",
    "    \n",
    "    if rewrite == False:\n",
    "        try:\n",
    "            feature_df = pd.read_hdf(save_to) # if there already exists file with features\n",
    "        except:\n",
    "            feature_df = pd.DataFrame()\n",
    "    else:\n",
    "        feature_df = pd.DataFrame()\n",
    "    \n",
    "    num_features = len(list_of_functions)\n",
    "    series = np.array(df[col_name], dtype = np.float)\n",
    "    for i in range(num_features):\n",
    "        function = list_of_functions[i].split(\"*\")[0]\n",
    "        window = window_sizes[i]\n",
    "        print(\"Calculating function \\\"{}\\\" with params: \\\"{}\\\" over the window: \\\"{}\\\"\"\\\n",
    "              .format(function, list_of_params[i], window))\n",
    "        \n",
    "        name_of_new_col = col_name + \"_\" + list_of_functions[i] + \"_\" + str(window)\n",
    "        if name_of_new_col not in list(feature_df.columns) or rewrite == True:\n",
    "            res = rolling_window(series, window_sizes[i], stride, function, params = list_of_params[i])\n",
    "            feature_df[name_of_new_col] = res\n",
    "            \n",
    "    feature_df.to_hdf(save_to, key='df')\n",
    "        \n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating function \"np.max\" with params: \"None\" over the window: \"1000\"\n",
      "Calculating function \"np.min\" with params: \"None\" over the window: \"1000\"\n",
      "Calculating function \"abs_energy\" with params: \"None\" over the window: \"1000\"\n",
      "Calculating function \"np.std\" with params: \"None\" over the window: \"1000\"\n",
      "Calculating function \"quantile\" with params: \"{'q': 0.6}\" over the window: \"1000\"\n",
      "Calculating function \"quantile\" with params: \"{'q': 0.8}\" over the window: \"1000\"\n",
      "Calculating function \"mean_second_derivative_central\" with params: \"None\" over the window: \"1000\"\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_hdf('/home/pavel/Documents/0Research/Projects/LANL-Earthquake/data/sample.h5', key = 'df'))\n",
    "df.columns = [\"s\",\"y\"]\n",
    "\n",
    "list_of_functions = [\"np.max\",'np.min', \"abs_energy\",\"np.std\", \\\n",
    "                     \"quantile*1\", \"quantile*2\", \"mean_second_derivative_central\"]\n",
    "list_of_params = [None, None, None, None, {\"q\" : 0.6}, {\"q\" : 0.8}, None]\n",
    "window_sizes = len(list_of_functions)*[1000]\n",
    "\n",
    "stride = 500\n",
    "save_to = \"/home/pavel/Documents/0Research/Projects/LANL-Earthquake/data/featurised_sample.h5\"\n",
    "calc_data(df, \"s\", list_of_functions, list_of_params, window_sizes, stride, save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurised_df = pd.read_hdf(\"/home/pavel/Documents/0Research/Projects/LANL-Earthquake/data/featurised_sample.h5\", key = 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_np.max_1000</th>\n",
       "      <th>s_np.min_1000</th>\n",
       "      <th>s_abs_energy_1000</th>\n",
       "      <th>s_np.std_1000</th>\n",
       "      <th>s_quantile*1_1000</th>\n",
       "      <th>s_quantile*2_1000</th>\n",
       "      <th>s_mean_second_derivative_central_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>48807.0</td>\n",
       "      <td>4.734789</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>68491.0</td>\n",
       "      <td>6.378595</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.005010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>63616.0</td>\n",
       "      <td>5.915530</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.002004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>47781.0</td>\n",
       "      <td>4.539343</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>737293.0</td>\n",
       "      <td>26.686003</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.008016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_np.max_1000  s_np.min_1000  s_abs_energy_1000  s_np.std_1000  \\\n",
       "0           31.0          -26.0            48807.0       4.734789   \n",
       "1           31.0          -26.0            68491.0       6.378595   \n",
       "2           31.0          -17.0            63616.0       5.915530   \n",
       "3           21.0           -8.0            47781.0       4.539343   \n",
       "4          104.0          -98.0           737293.0      26.686003   \n",
       "\n",
       "   s_quantile*1_1000  s_quantile*2_1000  s_mean_second_derivative_central_1000  \n",
       "0                6.0                8.0                               0.001503  \n",
       "1                6.0                9.0                              -0.005010  \n",
       "2                7.0               10.0                              -0.002004  \n",
       "3                6.0                9.0                              -0.001503  \n",
       "4                7.0               16.0                               0.008016  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurised_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
