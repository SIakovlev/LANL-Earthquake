{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import os\n",
    "import h5py\n",
    "import dask.dataframe as dd\n",
    "import dask\n",
    "import tsfresh\n",
    "import plotly \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "plotly.tools.set_credentials_file(username='ptolmachev', api_key='Fs5sBFAg7YuBn52rzy6n')\n",
    "\n",
    "def downsample(df, take_every):\n",
    "    return df.loc[::take_every]\n",
    "\n",
    "def nice_plot(series):\n",
    "    fig = plt.figure(figsize = (16,4))\n",
    "    plt.grid(True)\n",
    "    try:\n",
    "        plt.plot(series.compute().tolist(), 'r-',linewidth = 2, alpha = 0.7)\n",
    "    except:\n",
    "        plt.plot(series.tolist(), 'r-',linewidth = 2, alpha = 0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./LANL-Earthquake-Prediction/train_downcasted.csv', index_col = False)\n",
    "print(df.info(memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ddfs = []\n",
    "for i in range(3):\n",
    "    ddfs.append(dd.read_csv('./LANL-Earthquake-Prediction/EQ_'+str(i+1)+'.csv'))\n",
    "#     print(ddfs[-1].s.pow(2).mean().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "data = [go.Scatter(y=downsample(ddfs[i], 10).compute().s+i*1000, opacity = 0.7) for i in range(3)]\n",
    "layout = dict(\n",
    "    title='Three Earthquakes'\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "plotly.offline.plot(fig, filename = \"Signals before the earthquakes.html\", auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddfs_downsampled_10 =  [downsample(ddfs[i], 100).compute() for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mean and std over windows\n",
    "\n",
    "data = [go.Scatter(y=windowed_operation(ddfs_downsampled_10[i].s, 100, \"np.std\")+i*100, opacity = 0.7) for i in range(3)]\n",
    "layout = dict(\n",
    "    title='Three Earthquakes (std)'\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "plotly.offline.plot(fig, filename = \"Signals before the earthquakes.html\", auto_open=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DASK featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FUNCTIONS FOR COMPUTING FEATURES\n",
    "\n",
    "# def ema_sum(x, alpha = 0.9): #custom made function\n",
    "#     coeff = np.array([alpha**i for i in range(len(x))])*(1-alpha)/(1-alpha**(len(x)))\n",
    "#     return np.sum([x*c for x,c in zip(x,coeff)]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_hdf('/home/pavel/Documents/0Research/Projects/LANL-Earthquake/data/sample.h5', key = 'df'))\n",
    "df.columns = [\"s\",\"y\"]\n",
    "\n",
    "def rolling_window(series, window_size, stride, function, params = None):\n",
    "    len_series = len(series)\n",
    "    num_iter = int(np.ceil((len_series-window_size)/stride)+1) \n",
    "    \n",
    "    if params is None:\n",
    "        kwargs = {}\n",
    "    else:\n",
    "        kwargs = params\n",
    "    \n",
    "    shape = series.shape[:-1] + (series.shape[-1] - window_size + 1, window_size)\n",
    "    strides = series.strides + (series.strides[-1],)\n",
    "    iterator = iter(np.lib.stride_tricks.as_strided(series, shape=shape, strides=strides)[::stride])\n",
    "    res = 0*np.empty(num_iter, dtype = np.float)\n",
    "    \n",
    "    if hasattr(tsfresh.feature_extraction.feature_calculators, function):\n",
    "        modifier = \"tsfresh.feature_extraction.feature_calculators.\"\n",
    "    else:\n",
    "        modifier = \"\"\n",
    "\n",
    "    expression = modifier + function + \"(next(iterator), **kwargs)\"\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        try:\n",
    "            res[i] = np.float(eval(expression))\n",
    "        except StopIteration:\n",
    "            return res[:i]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_data(df, list_of_functions, list_of_params, window_sizes, stride, save_to):\n",
    "    '''\n",
    "    Input: pandas array with columns 's' and 'y' \n",
    "    ('s' corresponds to time series and 'y' - to the regression label)\n",
    "    \n",
    "    saves new pandas dataframe in hdf5 extension to \"save_to\" location\n",
    "    where the columns are the calculated over the time series features from the \"list_of_function\"\n",
    "    using windows from \"window_sizes\" and having a spesified stride\n",
    "    '''\n",
    "    \n",
    "    #checks\n",
    "    if (len(list_of_functions) != len(list_of_params)) or (len(list_of_params) != len(window_sizes)):\n",
    "        raise ValueError(\"Parameters \\\"list_of_functions\\\", \\\n",
    "        \\\"list_of_params\\\" and \\\"window_sizes\\\" must have the same lengths!\")\n",
    "    if stride <=0 :\n",
    "        raise ValueError(\"The \\\"stride\\\" has to be a postivie number!\")\n",
    "    \n",
    "    try:\n",
    "        feature_df = pd.read_hdf(save_to) # if there already exists file with features\n",
    "    except:\n",
    "        feature_df = pd.DataFrame()\n",
    "    \n",
    "    num_features = len(list_of_functions)\n",
    "    series = np.array(df[\"s\"], dtype = np.float)\n",
    "    for i in range(num_features):\n",
    "        function = list_of_functions[i].split(\"*\")[0]\n",
    "        window = window_sizes[i]\n",
    "        print(\"Calculating function \\\"{}\\\" with params: \\\"{}\\\" over the window: \\\"{}\\\"\"\\\n",
    "              .format(function, list_of_params[i], window))\n",
    "        \n",
    "        name_of_col = list_of_functions[i] + \"_\" + str(window)\n",
    "        if name_of_col in list(feature_df.columns):\n",
    "            pass\n",
    "        else:\n",
    "            res = rolling_window(series, window_sizes[i], stride, function, params = list_of_params[i])\n",
    "            feature_df[name_of_col] = res\n",
    "            \n",
    "    feature_df.to_hdf(save_to, key='df')\n",
    "        \n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating function \"np.max\" with params: \"None\" over the window: \"1000\"\n",
      "Calculating function \"np.min\" with params: \"None\" over the window: \"1000\"\n",
      "Calculating function \"abs_energy\" with params: \"None\" over the window: \"1000\"\n",
      "Calculating function \"np.std\" with params: \"None\" over the window: \"1000\"\n",
      "Calculating function \"quantile\" with params: \"{'q': 0.6}\" over the window: \"1000\"\n",
      "Calculating function \"quantile\" with params: \"{'q': 0.8}\" over the window: \"1000\"\n",
      "Calculating function \"mean_second_derivative_central\" with params: \"None\" over the window: \"1000\"\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_hdf('/home/pavel/Documents/0Research/Projects/LANL-Earthquake/data/sample.h5', key = 'df'))\n",
    "df.columns = [\"s\",\"y\"]\n",
    "\n",
    "list_of_functions = [\"np.max\",'np.min', \"abs_energy\",\"np.std\", \\\n",
    "                     \"quantile*1\", \"quantile*2\", \"mean_second_derivative_central\"]\n",
    "list_of_params = [None, None, None, None, {\"q\" : 0.6}, {\"q\" : 0.8}, None]\n",
    "window_sizes = len(list_of_functions)*[1000]\n",
    "\n",
    "stride = 500\n",
    "save_to = \"/home/pavel/Documents/0Research/Projects/LANL-Earthquake/data/featurised_sample.h5\"\n",
    "calc_data(df, list_of_functions, list_of_params, window_sizes, stride, save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurised_df = pd.read_hdf(\"/home/pavel/Documents/0Research/Projects/LANL-Earthquake/data/featurised_sample.h5\", key = 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_energy_1000</th>\n",
       "      <th>np.max_1000</th>\n",
       "      <th>np.min_1000</th>\n",
       "      <th>np.std_1000</th>\n",
       "      <th>quantile_1000</th>\n",
       "      <th>mean_second_derivative_central_1000</th>\n",
       "      <th>quantile*1_1000</th>\n",
       "      <th>quantile*2_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48807.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>4.734789</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68491.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>6.378595</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.005010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63616.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>5.915530</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47781.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>4.539343</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>737293.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>26.686003</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abs_energy_1000  np.max_1000  np.min_1000  np.std_1000  quantile_1000  \\\n",
       "0          48807.0         31.0        -26.0     4.734789            8.0   \n",
       "1          68491.0         31.0        -26.0     6.378595            9.0   \n",
       "2          63616.0         31.0        -17.0     5.915530           10.0   \n",
       "3          47781.0         21.0         -8.0     4.539343            9.0   \n",
       "4         737293.0        104.0        -98.0    26.686003           16.0   \n",
       "\n",
       "   mean_second_derivative_central_1000  quantile*1_1000  quantile*2_1000  \n",
       "0                             0.001503              6.0              8.0  \n",
       "1                            -0.005010              6.0              9.0  \n",
       "2                            -0.002004              7.0             10.0  \n",
       "3                            -0.001503              6.0              9.0  \n",
       "4                             0.008016              7.0             16.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurised_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
