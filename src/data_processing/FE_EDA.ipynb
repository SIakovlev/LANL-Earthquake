{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import dask.dataframe as dd\n",
    "import dask\n",
    "import plotly\n",
    "from EQ_chunking import chunk_data_on_EQs\n",
    "import os, fnmatch\n",
    "plotly.tools.set_credentials_file(username='ptolmachev', api_key='Fs5sBFAg7YuBn52rzy6n')\n",
    "\n",
    "def nice_plot(series):\n",
    "    fig = plt.figure(figsize = (16,4))\n",
    "    plt.grid(True)\n",
    "    try:\n",
    "        plt.plot(series.compute().tolist(), 'r-',linewidth = 2, alpha = 0.7)\n",
    "    except:\n",
    "        plt.plot(series.tolist(), 'r-',linewidth = 2, alpha = 0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dir_contains_EQs(data_path, EQs_num):\n",
    "    list_dir = os.list_dir(data_path)\n",
    "    for i in range(len(list_dir)):\n",
    "        subdir_path = path_to_data + \"/\" + list_dir[i]\n",
    "        if [os.path.isfile(subdir_path + \"/\" + \"EQ_\" + str(num)) for num in EQs_num].all() == True:\n",
    "            return list_dir(i)\n",
    "    return None\n",
    "\n",
    "def find(pattern, path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if fnmatch.fnmatch(name, pattern):\n",
    "                result.append(os.path.join(root, name))\n",
    "    if len(result) == 0:\n",
    "        return None\n",
    "    return result[0]\n",
    "            \n",
    "\n",
    "def plot_data(function, params, **kwargs):\n",
    "    data_path = kwargs['path_to_data']\n",
    "    list_of_EQs_to_plot = kwargs['EQs_num']\n",
    "    \n",
    "    #Preparation part\n",
    "    EQ_dir = find_dir_contains_EQs(data_path, EQs_num)\n",
    "    if EQ_dir is None:\n",
    "        print(\"Need to split the data into the chunks first! \\n\")\n",
    "        save_chunks_to = data_path + \"/EQs\"\n",
    "        print(\"Splitting the data, and saving it to {}\".format(save_chunks_to))\n",
    "        full_data_file = find('train.h5', data_path)\n",
    "        if full_data_file is None:\n",
    "            full_data_file = find('train.csv', data_path)\n",
    "            \n",
    "        chunk_data_on_EQs(full_data_file, save_chunks_to)\n",
    "    \n",
    "    # plotting part\n",
    "    dataframes = [pd.read_hdf(path_to_data + \"/EQ_\" + str(EQ) + \".h5\") for EQ in list_of_EQs_to_plot]\n",
    "    df = pd.concat(dataframes)\n",
    "    names = [feature_name, \"downsampled_signal\", 'ttf']\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pavel/Documents/0Research/Projects/LANL-Earthquake/data/train.csv'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find(\"train.csv\",\"/home/pavel/Documents/0Research/Projects/LANL-Earthquake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
