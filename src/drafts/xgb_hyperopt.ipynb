{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best result:\n",
    "\n",
    "Training with params: {'booster': 'gbtree', 'colsample_bytree': 0.5, 'eta': 0.185, 'eval_metric': 'mae', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 20, 'objective': 'gpu:reg:linear', 'seed': 314159265, 'silent': 1, 'subsample': 0.6000000000000001, 'tree_method': 'gpu_hist'}\n",
    "Score: 2.031294080039467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')\n",
    "from folds.folds import CustomFold\n",
    "from hyperopt import fmin, hp, tpe, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('../../data/e3.h5', key='table')\n",
    "\n",
    "train_data = df.drop(['ttf'], axis=1)\n",
    "y_train_data = df['ttf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params, n=10):\n",
    "    print(f\"Training with params: {params}\")\n",
    "\n",
    "    np.random.seed(0)\n",
    "    folds = CustomFold(n_splits=9, shuffle=True, fragmentation=0, pad=150)\n",
    "    loss_list = []\n",
    "    for _ in range(n):\n",
    "        for fold_n, (train_index, valid_index) in enumerate(folds.split(train_data)):\n",
    "            X_train, X_valid = train_data.iloc[train_index], train_data.iloc[valid_index]\n",
    "            y_train, y_valid = y_train_data.iloc[train_index], y_train_data.iloc[valid_index]\n",
    "\n",
    "            preprocessor = preprocessing.StandardScaler()\n",
    "            preprocessor.fit(X_train)\n",
    "            X_train = pd.DataFrame(preprocessor.transform(X_train))\n",
    "            X_valid = pd.DataFrame(preprocessor.transform(X_valid))\n",
    "\n",
    "            model = XGBRegressor(**params)\n",
    "            model.fit(X_train.values, y_train.values)\n",
    "            predictions = model.predict(X_valid.values)\n",
    "            loss_list.append(mean_absolute_error(predictions, y_valid))\n",
    "\n",
    "    loss = np.mean(loss_list)\n",
    "    print(f\"Score: {loss}\")\n",
    "    return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(random_state=314159265):\n",
    "    \"\"\"\n",
    "    This is the optimization function that given a space (space here) of\n",
    "    hyperparameters and a scoring function (score here), finds the best hyperparameters.\n",
    "    \"\"\"\n",
    "\n",
    "    space = {\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators', 10, 300, 5)),\n",
    "        'eta': hp.quniform('eta', 0.005, 0.5, 0.005),\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 1, 5, 1)),\n",
    "        'min_child_weight': scope.int(hp.quniform('min_child_weight', 1, 10, 1)),\n",
    "        'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "        'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "        'eval_metric': 'mae',\n",
    "        'objective': 'gpu:reg:linear',\n",
    "        'booster': 'gbtree',\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'silent': 1,\n",
    "        'seed': random_state\n",
    "    }\n",
    "\n",
    "    best = fmin(score,\n",
    "                space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=2000)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams = optimize()\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(best_hyperparams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
